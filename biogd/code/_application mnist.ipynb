{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U tensorflow>=1.8.0\n",
    "#!pip install foolbox\n",
    "#!pip install tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import foolbox\n",
    "\n",
    "import talos as ta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Layer, Dropout, Activation\n",
    "from keras import backend as K\n",
    "from talos.model.early_stopper import early_stopper\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "fashion_mnist_labels = [\"digit 0\",  \n",
    "                        \"digit 1\",      \n",
    "                        \"digit 2\",     \n",
    "                        \"digit 3\",        \n",
    "                        \"digit 4\",         \n",
    "                        \"digit 5\",       \n",
    "                        \"digit 6\",         \n",
    "                        \"digit 7\",       \n",
    "                        \"digit 8\",          \n",
    "                        \"digit 9\"]   \n",
    "\n",
    "img_index = 1\n",
    "label_index = y_train[img_index]\n",
    "print (\"y = \" + str(y_train[5]) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of train data : \" + str(len(x_train)))\n",
    "print(\"Number of test data : \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val) = x_train[10000:], x_train[:10000] \n",
    "(y_train, y_val) = y_train[10000:], y_train[:10000]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = y_test\n",
    "# One-hot encode the labels\n",
    "nb_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_val.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "print(y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioSigmoid(Layer):\n",
    "    def __init__(self, a, b, r, **kwargs):\n",
    "        super(BioSigmoid, self).__init__(**kwargs)\n",
    "        self.a = K.cast_to_floatx(a)\n",
    "        self.b = K.cast_to_floatx(b)\n",
    "        self.r = K.cast_to_floatx(r)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.a + (self.b - self.a)*K.sigmoid(self.r * inputs)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'a': float(self.a), 'b': float(self.b), 'r': float(self.r)}\n",
    "        base_config = super(BioSigmoid, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "    \n",
    "class BioSoftmax(Layer):\n",
    "    def __init__(self, a, b, r, axis=-1, **kwargs):\n",
    "        super(BioSoftmax, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.axis = axis\n",
    "        self.a = K.cast_to_floatx(a)\n",
    "        self.b = K.cast_to_floatx(b)\n",
    "        self.r = K.cast_to_floatx(r)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.a + (self.b - self.a)*K.softmax(self.r * inputs, axis=self.axis)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'axis': self.axis}\n",
    "        base_config = super(BioSoftmax, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    print(params)\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(x_train.shape[1], input_dim = x_train.shape[1]))\n",
    "    model.add(BioSigmoid(a=params['a'], b=params['b'], r=params['r'])) \n",
    "    model.add(Dense(10))\n",
    "    model.add(BioSigmoid(a=params['a'], b=params['b'], r=params['r']))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BioSoftmax(a=params['a'], b=params['b'], r=params['r']))  \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=False)\n",
    "\n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    callbacks=[checkpointer,early_stopper(params['epochs'], patience=10)],\n",
    "                    verbose = 1,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    \n",
    "    return out, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize with Talos here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x_train, x_val), axis=0)\n",
    "y = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'a': np.linspace(0.0,0.15,10),\n",
    "     'b': np.linspace(0.85,1.0,10),\n",
    "     'r': np.linspace(0.5,5.1,5),\n",
    "     'batch_size': [25],\n",
    "     'epochs': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "h = ta.Scan(x, y, params=p,\n",
    "            model=build_model,\n",
    "            grid_downsample=.15,\n",
    "            dataset_name='keras-!mnist_adv',\n",
    "            experiment_no='9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = ta.Reporting(h)\n",
    "print(l.high())\n",
    "print(l.best_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('keras-!mnist_adv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(4)\n",
    "print(df.sort_values('val_acc', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_best_model():\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    best_a = 0.13\n",
    "    best_b = 0.9333\n",
    "    best_r = 2.8\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(x_train.shape[1], input_dim = x_train.shape[1]))\n",
    "    model.add(BioSigmoid(a = best_a, b = best_b, r = best_r))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BioSigmoid(a = best_a, b = best_b, r = best_r))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BioSoftmax(a = best_a, b = best_b, r = best_r))  \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_default_model():\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    best_a = 0.0\n",
    "    best_b = 1.0\n",
    "    best_r = 1.0\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(x_train.shape[1], input_dim = x_train.shape[1]))\n",
    "    model.add(BioSigmoid(a = best_a, b = best_b, r = best_r))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BioSigmoid(a = best_a, b = best_b, r = best_r))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BioSoftmax(a = best_a, b = best_b, r = best_r))  \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = build_best_model()\n",
    "model_def = build_default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='model_best.weights.best.hdf5', verbose = 1, save_best_only=False)\n",
    "model_best.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=25,\n",
    "         epochs=1,\n",
    "         validation_data=(x_val, y_val),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='model_def.weights.best.hdf5', verbose = 1, save_best_only=False)\n",
    "model_def.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=25,\n",
    "         epochs=1,\n",
    "         validation_data=(x_val, y_val),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "score_best = model_best.evaluate(x_test, y_test, verbose=0)\n",
    "score_def = model_def.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('\\n', 'Test accuracy (best):', score_best[1])\n",
    "print('\\n', 'Test accuracy (default):', score_def[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and generate adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "foolbox_model_best = foolbox.models.TensorFlowModel.from_keras(model_best,bounds = (0.0, 1.0))\n",
    "foolbox_model_def = foolbox.models.TensorFlowModel.from_keras(model_def,bounds = (0.0, 1.0))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "w, h = 28, 28\n",
    "\n",
    "target = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### :: best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_norm_best = []\n",
    "target_adv_best = []\n",
    "pred_norm_best = []\n",
    "pred_adv_best = []\n",
    "\n",
    "attack_fgsm = foolbox.attacks.FGSM(foolbox_model_best)\n",
    "count = 0\n",
    "sum_best = 0\n",
    "\n",
    "for i in range(1,len(y_classes)):\n",
    "    if(y_classes[i]==target):\n",
    "        print(\"Normal\")\n",
    "        image = x_test[i]\n",
    "        target_norm_best.append(np.argmax(foolbox_model_best.predictions(image)))\n",
    "        pred = model_best.predict(image.reshape(1,x_test.shape[1]))\n",
    "        pred_norm_best.append(pred[0][y_classes[i]])\n",
    "        \n",
    "        print(\"Adversarial\")\n",
    "        adversarial = attack_fgsm(image,label = y_classes[i])\n",
    "        target_adv_best.append(np.argmax(foolbox_model_best.predictions(adversarial)))                        \n",
    "        adver_pred = model_best.predict(adversarial.reshape(1,x_test.shape[1]))\n",
    "        pred_adv_best.append(adver_pred[0][y_classes[i]])\n",
    "\n",
    "        count+=1\n",
    "        sum_best+=(target_norm_best != target_adv_best)\n",
    "        print(\"-.-\", count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### :: default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_norm_def = []\n",
    "target_adv_def = []\n",
    "pred_norm_def = []\n",
    "pred_adv_def = []\n",
    "\n",
    "attack_fgsm = foolbox.attacks.FGSM(foolbox_model_def)\n",
    "count = 0\n",
    "sum_def = 0\n",
    "\n",
    "for i in range(1,len(y_classes)):\n",
    "    if(y_classes[i]==target):\n",
    "        print(\"Normal\")\n",
    "        image = x_test[i]\n",
    "        target_norm_def.append(np.argmax(foolbox_model_def.predictions(image)))\n",
    "        pred = model_def.predict(image.reshape(1,x_test.shape[1]))\n",
    "        pred_norm_def.append(pred[0][y_classes[i]])\n",
    "        \n",
    "        print(\"Adversarial\")\n",
    "        adversarial = attack_fgsm(image,label = y_classes[i])\n",
    "        target_adv_def.append(np.argmax(foolbox_model_def.predictions(adversarial)))                        \n",
    "        adver_pred = model_def.predict(adversarial.reshape(1,x_test.shape[1]))\n",
    "        pred_adv_def.append(adver_pred[0][y_classes[i]])\n",
    "\n",
    "        count+=1\n",
    "        sum_def+=(target_norm_def != target_adv_def)\n",
    "        print(\"-.-\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### :: print and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bio algorithm\")\n",
    "print(\"Target:\", target)\n",
    "print(\"Number of misclassified examples:\", sum_best)\n",
    "print(\"Number of target examples:\", count)\n",
    "print(Counter(target_norm_best),\"norm\")\n",
    "print(Counter(target_adv_best),\"adv\")\n",
    "\n",
    "print(\"-.-\")\n",
    "\n",
    "print(\"Default algorithm\")\n",
    "print(\"Target:\",target)\n",
    "print(\"Number of misclassified examples:\", sum_def)\n",
    "print(\"Number of target examples:\", count)\n",
    "print(Counter(target_norm_def),\"norm\")\n",
    "print(Counter(target_adv_def),\"adv\")\n",
    "\n",
    "cols = ['target_norm_best','target_adv_best',\n",
    "        'target_norm_def','target_adv_def'\n",
    "        'pred_norm_best','pred_norm_def',\n",
    "        'misclass_num_best','misclass_num_def', \"target_num_class\",\n",
    "        'test_acc_best','test_acc_adv']\n",
    "df_def = pd.DataFrame({\"target_norm_best\" : target_norm_best,\n",
    "                       \"target_adv_best\" : target_adv_best,\n",
    "                       \"target_norm_def\" : target_norm_def, \n",
    "                       \"target_adv_def\" : target_adv_def,\n",
    "                       \"pred_adv_best\" : pred_adv_best,\n",
    "                       \"pred_adv_def\" : pred_adv_def,\n",
    "                       \"misclass_num_best\" : np.ones(len(pred_adv_best))*sum_best,\n",
    "                       \"misclass_num_def\" : np.ones(len(pred_adv_def))*sum_def,\n",
    "                       \"target_num_class\" : np.ones(len(pred_adv_def))*count,\n",
    "                       \"test_acc_best\": np.ones(len(pred_adv_best))*score_best[1],\n",
    "                       \"test_acc_def\": np.ones(len(pred_adv_def))*score_def[1]\n",
    "                      })\n",
    "df_def.to_csv('keras-!mnist_adv-results'+str(target)+'.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
